{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"onebuilding-scraper","text":"<p>This is a repository for scraping data from climate.onebuilding.org.</p>"},{"location":"modules/","title":"Modules","text":"<p>A module for scraping the climate.onebuilding.org website for EPW files.</p>"},{"location":"modules/#onebuilding_scraper.utils.download_zip_and_unzip","title":"<code>download_zip_and_unzip(file, output_dir, client)</code>  <code>async</code>","text":"<p>Downloads a zip file from a given URL, extracts its contents, and returns the path to the extracted EPW file.</p> <p>Parameters:</p> Name Type Description Default <code>file</code> <code>str</code> <p>The URL of the zip file to download.</p> required <code>output_dir</code> <code>Path</code> <p>The directory where the extracted files will be saved.</p> required <code>client</code> <code>AsyncClient</code> <p>The HTTP client to use for the request.</p> required <p>Returns:</p> Name Type Description <code>status_code</code> <code>int</code> <p>The status code.</p> <code>out_epw</code> <code>Path | Exception</code> <p>The path to the extracted EPW file or an exception if an error occurred.</p> Source code in <code>onebuilding_scraper\\utils.py</code> <pre><code>async def download_zip_and_unzip(\n    file: str, output_dir: Path, client: httpx.AsyncClient\n):\n    \"\"\"Downloads a zip file from a given URL, extracts its contents, and returns the path to the extracted EPW file.\n\n    Args:\n        file (str): The URL of the zip file to download.\n        output_dir (Path): The directory where the extracted files will be saved.\n        client (httpx.AsyncClient): The HTTP client to use for the request.\n\n    Returns:\n        status_code (int): The status code.\n        out_epw (Path | Exception): The path to the extracted EPW file or an exception if an error occurred.\n    \"\"\"\n    out_zip = output_dir / Path(file)\n    out_folder = out_zip.parent / out_zip.stem\n    out_epw = out_folder / f\"{out_zip.stem}.epw\"\n    if not (out_epw).exists():\n        out_zip.parent.mkdir(parents=True, exist_ok=True)\n        try:\n            res = await client.get(file)\n        except Exception as e:\n            return (-1, e)\n        try:\n            with open(out_zip, \"wb\") as f:\n                f.write(res.content)\n            out_folder.mkdir(parents=True, exist_ok=True)\n            shutil.unpack_archive(out_zip, out_folder)\n            out_zip.unlink()\n\n        except Exception as e:\n            out_zip.unlink(missing_ok=True)\n            shutil.rmtree(out_folder)\n            return (-2, e)\n    else:\n        await asyncio.sleep(0.01)\n    return (0, out_epw)\n</code></pre>"},{"location":"modules/#onebuilding_scraper.utils.generate_paths","title":"<code>generate_paths(client)</code>  <code>async</code>","text":"<p>Generate a list of file paths.</p> <p>Parameters:</p> Name Type Description Default <code>client</code> <code>AsyncClient</code> <p>An instance of httpx.AsyncClient.</p> required <p>Returns:</p> Name Type Description <code>files</code> <code>list[str]</code> <p>A list of file paths.</p> Source code in <code>onebuilding_scraper\\utils.py</code> <pre><code>async def generate_paths(client: httpx.AsyncClient):\n    \"\"\"Generate a list of file paths.\n\n    Args:\n        client (httpx.AsyncClient): An instance of httpx.AsyncClient.\n\n    Returns:\n        files (list[str]): A list of file paths.\n    \"\"\"\n    regions = await get_root(client)\n    subregion_promises = [get_subregions(region, client) for region in regions]\n    subregions = [\n        r\n        for region in cast(\n            list[list[str]],\n            await atqdm.gather(*subregion_promises),  # pyright: ignore [reportUnknownMemberType]\n        )\n        for r in region\n    ]\n    file_promises = [get_file_list(subregion, client) for subregion in subregions]\n    files = [\n        f\n        for subregion in cast(\n            list[list[str]],\n            await atqdm.gather(*file_promises),  # pyright: ignore [reportUnknownMemberType]\n        )\n        for f in subregion\n    ]\n    return files\n</code></pre>"},{"location":"modules/#onebuilding_scraper.utils.get_file_list","title":"<code>get_file_list(url, client)</code>  <code>async</code>","text":"<p>Retrieves a list of file URLs from a given URL.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL to scrape for file URLs.</p> required <code>client</code> <code>AsyncClient</code> <p>The HTTP client to use for the request.</p> required <p>Returns:</p> Type Description <code>list[str]</code> <p>List[str]: A list of file URLs.</p> Source code in <code>onebuilding_scraper\\utils.py</code> <pre><code>async def get_file_list(url: str, client: httpx.AsyncClient) -&gt; list[str]:\n    \"\"\"Retrieves a list of file URLs from a given URL.\n\n    Args:\n        url (str): The URL to scrape for file URLs.\n        client (httpx.AsyncClient): The HTTP client to use for the request.\n\n    Returns:\n        List[str]: A list of file URLs.\n\n    \"\"\"\n    res = await client.get(url)\n    soup = BeautifulSoup(res.content, \"html.parser\")\n    # get the table element with class \"file-table\"\n    table = soup.find(\"table\", summary=\"file table\")\n    if not isinstance(table, Tag):\n        flist: list[str] = []\n        return flist\n    a_tags = table.find_all(\"a\", href=re.compile(r\".*\\.zip\"))\n    urls: list[str] = []\n    for tag in a_tags:\n        resource_url: Path = Path(url).parent / tag[\"href\"]\n        urls.append(resource_url.as_posix())\n    return urls\n</code></pre>"},{"location":"modules/#onebuilding_scraper.utils.get_root","title":"<code>get_root(client)</code>  <code>async</code>","text":"<p>Retrieves the root elements from the client.</p> <p>Parameters:</p> Name Type Description Default <code>client</code> <code>AsyncClient</code> <p>The HTTP client.</p> required <p>Returns:</p> Name Type Description <code>regions</code> <code>list[str]</code> <p>A list of regions extracted from the root elements.</p> Source code in <code>onebuilding_scraper\\utils.py</code> <pre><code>async def get_root(client: httpx.AsyncClient):\n    \"\"\"Retrieves the root elements from the client.\n\n    Args:\n        client (httpx.AsyncClient): The HTTP client.\n\n    Returns:\n        regions (list[str]): A list of regions extracted from the root elements.\n    \"\"\"\n    home = await client.get(\"/default.html\")\n    soup = BeautifulSoup(home.content, \"html.parser\")\n    # find all a tags with hrefs that start with \"WMO_REGION_\"\n    regions = list({\n        cast(str, a[\"href\"])\n        for a in soup.find_all(\"a\", href=re.compile(r\"WMO_Region_\"))\n    })\n    return regions\n</code></pre>"},{"location":"modules/#onebuilding_scraper.utils.get_subregions","title":"<code>get_subregions(url, client)</code>  <code>async</code>","text":"<p>Retrieves the subregions from the given URL.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL to scrape for subregions.</p> required <code>client</code> <code>AsyncClient</code> <p>The HTTP client to use for the request.</p> required <p>Returns:</p> Type Description <code>list[str]</code> <p>list[str]: A list of subregions found in the URL.</p> Source code in <code>onebuilding_scraper\\utils.py</code> <pre><code>async def get_subregions(url: str, client: httpx.AsyncClient) -&gt; list[str]:\n    \"\"\"Retrieves the subregions from the given URL.\n\n    Args:\n        url (str): The URL to scrape for subregions.\n        client (httpx.AsyncClient): The HTTP client to use for the request.\n\n    Returns:\n        list[str]: A list of subregions found in the URL.\n    \"\"\"\n    res = await client.get(url)\n    soup = BeautifulSoup(res.content, \"html.parser\")\n    # get any a tags which are in td tags\n    tags: list[Tag] = soup.find_all(\"td\")\n    regions: list[str] = []\n    for tag in tags:\n        a = tag.find(\"a\")\n        if not isinstance(a, Tag):\n            continue\n        href = cast(str, a[\"href\"])\n        if href.endswith(\"html\"):\n            child_region = Path(url).parent / href\n            regions.append(child_region.as_posix())\n\n    return regions\n</code></pre>"},{"location":"modules/#onebuilding_scraper.utils.make_row_dict","title":"<code>make_row_dict(path)</code>","text":"<p>Parses the contents of a file at the given path and returns a dictionary containing relevant information.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>The path to the file.</p> required <p>Returns:</p> Name Type Description <code>metadata</code> <code>dict[str, int | bool | float]</code> <p>A dictionary containing the following information: - name (str): The name of the file. - location (str): The location in the format \"POINT(lon lat)\". - path (str): The path to the file. - country (str): The country name. - province (str): The province name. - city (str): The city name. - lat (float): The latitude. - lon (float): The longitude. - wmo (str): The WMO code. - tz (float): The time zone. - TM3 (bool): True if the file is TMY3, False otherwise. - TMx (bool): True if the file is TMYx, False otherwise. - year (int): The year. - start_year (int): The start year (if applicable). - end_year (int): The end year (if applicable).</p> Source code in <code>onebuilding_scraper\\utils.py</code> <pre><code>def make_row_dict(path: str):\n    \"\"\"Parses the contents of a file at the given path and returns a dictionary containing relevant information.\n\n    Args:\n        path (str): The path to the file.\n\n    Returns:\n        metadata (dict[str, int | bool | float]): A dictionary containing the following information:\n            - name (str): The name of the file.\n            - location (str): The location in the format \"POINT(lon lat)\".\n            - path (str): The path to the file.\n            - country (str): The country name.\n            - province (str): The province name.\n            - city (str): The city name.\n            - lat (float): The latitude.\n            - lon (float): The longitude.\n            - wmo (str): The WMO code.\n            - tz (float): The time zone.\n            - TM3 (bool): True if the file is TMY3, False otherwise.\n            - TMx (bool): True if the file is TMYx, False otherwise.\n            - year (int): The year.\n            - start_year (int): The start year (if applicable).\n            - end_year (int): The end year (if applicable).\n    \"\"\"\n    with open(path) as f:\n        epw = f.readline()\n    data = epw.split(\",\")\n    city = data[1]\n    province = data[2]\n    country = data[3]\n    lat = float(data[-4])\n    lon = float(data[-3])\n    location = f\"POINT({lon} {lat})\"\n    tz = float(data[-2])\n    file_path = Path(path)\n    name = file_path.stem\n    is_tmy3 = \"tmy3\" in name.lower()\n    is_tmyx = \"tmyx\" in name.lower()\n    wmo_match = re.compile(r\".*\\.(\\d{6})\").match(name)\n    wmo = wmo_match.group(1) if wmo_match else None\n    year_pattern = r\"(?&lt;![0-9])(?:20|19)\\d{2}(?![0-9])\"\n    applicable_years = re.findall(year_pattern, name)\n    start_year = int(applicable_years[0]) if len(applicable_years) == 2 else None\n    end_year = int(applicable_years[1]) if len(applicable_years) == 2 else None\n    year = int(applicable_years[0]) if len(applicable_years) == 1 else None\n\n    data = {\n        \"name\": name,\n        \"location\": location,\n        \"path\": path,\n        \"country\": country,\n        \"province\": province,\n        \"city\": city,\n        \"lat\": lat,\n        \"lon\": lon,\n        \"wmo\": wmo,\n        \"tz\": tz,\n        \"TM3\": is_tmy3,\n        \"TMx\": is_tmyx,\n        \"year\": year,\n        \"start_year\": start_year,\n        \"end_year\": end_year,\n    }\n    return data\n</code></pre>"}]}